%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Journal Article
% LaTeX Template
% Version 1.3 (9/9/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[twoside]{article}

\usepackage{lipsum} % Package to generate dummy text throughout this template

\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\linespread{1.05} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics

\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} % Document margins
\usepackage{multicol} % Used for the two-column layout of the document
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{float} % Required for tables and figures in the multi-column environment - they need to be placed in specific locations with the [H] (e.g. \begin{table}[H])
\usepackage{hyperref} % For hyperlinks in the PDF

\usepackage{lettrine} % The lettrine is the first enlarged letter at the beginning of the text
\usepackage{paralist} % Used for the compactitem environment which makes bullet points with less space between them

\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text

\usepackage{titlesec} % Allows customization of titles
\renewcommand\thesection{\Roman{section}} % Roman numerals for the sections
\renewcommand\thesubsection{\Roman{subsection}} % Roman numerals for subsections
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{} % Change the look of the section titles
\titleformat{\subsection}[block]{\large}{\thesubsection.}{1em}{} % Change the look of the section titles

\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{} % Blank out the default header
\fancyfoot{} % Blank out the default footer
\fancyhead[C]{Running title $\bullet$ March 2015 $\bullet$ Vol. XXI, No. 1} % Custom header text
\fancyfoot[RO,LE]{\thepage} % Custom footer text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{\vspace{-15mm}\fontsize{24pt}{10pt}\selectfont\textbf{Extraction of Relevant Characteristics for Message Comparison}} % Article title

\author{
\large
\textsc{Axel Alejandro Garcia Fuentes}\thanks{A thank you or further information}\\[2mm] % Your name
\normalsize Universidad Autonoma de Guadalajara \\ % Your institution
\normalsize \href{mailto:axel.garcia@edu.uag.mx}{axel.garcia@edu.uag.mx} % Your email address
\vspace{-5mm}
}
\date{}

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Insert title

\thispagestyle{fancy} % All pages have headers and footers

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\begin{abstract}

%\noindent \lipsum[1] % Dummy abstract text
There are aspects in the human communication that differentiate two phrases within a determined context. When the context varies the distinction between the same two phrases may change, too. Natural language is ambiguous, however, there are key elements in the natural statements that may provide enough information to fairly compare whatever two sentences in natural language. Once that capability is available for text processors computers may be capable of classify text by meaning rather than by text similarity.

\end{abstract}

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\begin{multicols}{2} % Two-column layout throughout the main article text

\section{Introduction}
\lettrine[nindent=0em,lines=3]{T}his document is intended to discuss the theoretical plausibility of the implementation of a system capable of extract relevant aspects of a short message in Spanish. The message length of the text to be processed should be at most 500 % Confirmar valor
characters. That length was determined based on the average message length of the inquiries submitted to the Federal Institute of Information Access and Data Protection in Mexico(IFAI in Spanish)\cite{IFAI:2014} . Taking that as base, it was observed that the turn around time in which the information is sent to requestors has a mode of 20 working days and 28 natural days. There are eight extra natural days requestors should tolerate when requesting information through the IFAI system. Since that is the communicated waiting period it is not really a problem but an improvement area.

The real question is are modern information technology not enough to create a system that can help trespassing the barrier of human capabilities?, is it possible to create a system that can compare a given question against a database of previously asked questions and find out what questions are close enough to mean most likely the same thing?. 

The state of the art for natural language processing has achieved important progress in answering questions algorithms% Enumerate Agichtein, E., Lawrence, S., and Gravano, L. 2004. Learning to find answers to questions on the web.%ACM Transactions on Internet Technology 4(2): 129?162.%Bendersky, M., and Croft, B. 2008. Discovering key concepts in verbose queries. In Proceedings%of the 31st Annual International ACM SIGIR Conference on Research and Development in%Information Retrieval, Singapore, pp. 491?498.%Bilotti, M., Ogilvie, P., Callan, J., and Nyberg, E. 2007. Structured retrieval for question answering.%In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and%Development in Information Retrieval, Amsterdam, The Netherlands, pp. 351?358.%Breimann, L., Friedman, J., Ohlsen, R., and Stone, C. 1984. Classification and Regression Trees.%Wadsworth and Brooks.%Brill, E., Dumais, S., and Banko, M. 2002. An analysis of the AskMSR question-answering%system. In Proceedings of Empirical Methods in Natural Language Processing (EMNLP 2002),%Morristown, N.J., USA, pp. 257?264
. 
\section{Method}
The way the proposed algorithm is expected to work is by extracting a description vector from the short messages being processed and computing the distance with respect other questions previously made. As the questions and answers database grows the searches will take more time each time. To overcome that situation, the questions will be classified based on a hashing function like minhashing. The algorithm is the following: 
\begin{enumerate}
\item Question in natural language \emph{Q} is entered to the system.
\item Information extraction algorithm generates the description vector \emph{v} from \emph{Q}.
\item Hashing function \emph{m()} is used to generate a hashing value \emph{h} from \emph{v}.
\item The hashing value \emph{h} is looked for in the questions database.
\item if it is found, then the answer associated to that question is selected as proposed answer and the system will claim \emph{Q -> A}
\item If it is not found, then \emph{A} is empty and it is associated to \emph{h}.
\item \emph{h} is added to the questions database.
\end{enumerate}

Whenever an empty answer is found in the system, human expert intervention is requested. Once the question is solved by the expert human, the empty entry for that answer is replaced by the provided response.

\section{Information Retrieval Dimensions}
The function of the words the processed text is composed of is different. Some of those words hold more information than others. As \cite{Monz:2010} suggests, the words with higher inverted document frequency (idf) will be preferred to determine the topic of the short text % citar trabajos que hablen de este tema.
:
\begin{equation}
\label{eq:idf}
idf(t) = log{N/df(t)}
\end{equation}
Where \emph{N} is the number of documents in the collection and \emph{df(t)} is the number of documents in which \emph{t} occurs.

Equation \ref{eq:idf} will help to determine a list of candidate words for to identify the message topic. However, that equation measures frequency not unambiguity. Reference \cite{saif.ea:2012} proposes a method to identify unambiguous keywords. That method can be used to count how many unambiguous terms a question has. That in turn can be a dimension of the description vector. That reference mentions unambiguous key terms tend to have higher IDF (Inverted Document Index) than ambiguous key terms. However, it mentions there is an overlap in the mid-lower IDF. That overlap makes it hard to use IDF to separate unambiguous from ambiguous key terms. \cite{saif.ea:2012} mentions IDF can be used to identify misspellings.

Reference \cite{saif.ea:2012} interprets Caps First Ratio as names. This can be used to differentiate a question that talks about names from another that does not. This can be another dimension.

Reference \cite{saif.ea:2012} shows that stop words and auxiliary language is less often in query streams. If those elements are being used less then they offer little information and can be neglected. The current work proposes to ignore stop words during description vector creation.

Reference \cite{saif.ea:2012} used Yahoo! Term Extractor API, Stanford Named Entity Recognizer

From reference \cite{saif.ea:2012} mentions for some real world applications they cannot afford extracting an incorrect keyword from a noisy text.


%------------------------------------------------
\begin{description}
\item[Unambiguous Words] \hfill \\
Number of unambiguous worlds in phrase.  
\item[Capitalized Words] \hfill \\
Number of capitalized worlds in phrase(potential names). 
\item[SER] \hfill \\
It tells how often a given keyword shows up by itself in the search box.
\label{table:lst_dimensions} % is used to refer this table in the text
\end{description}


%------------------------------------------------

%\section{Results}

%\begin{table}[H]
%\caption{Example table}
%\centering
%\begin{tabular}{llr}
%\toprule
%\multicolumn{2}{c}{Name} \\
%\cmidrule(r){1-2}
%First name & Last Name & Grade \\
%\midrule
%John & Doe & $7.5$ \\
%Richard & Miles & $2$ \\
%\bottomrule
%\end{tabular}
%\end{table}

%\begin{equation}
%\label{eq:emc}
%e = mc^2
%\end{equation}

%\lipsum[6] % Dummy text

%------------------------------------------------

%\section{Discussion}

%\subsection{Subsection One}

%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------

%\begin{thebibliography}{99} % Bibliography - this is intentionally simple in this template

%\bibitem[Figueredo and Wolf, 2009]{Figueredo:2009dg}
%Figueredo, A.~J. and Wolf, P. S.~A. (2009).
%\newblock Assortative pairing and life history strategy - a cross-cultural
%  study.
%\newblock {\em Human Nature}, 20:317--330.
 
%\end{thebibliography}

% Steps for typesetting document with Bibtex:
% 1) Latex
% 2) Bibtex
% 3) Latex
% 4) Latex

\bibliographystyle{apalike} % acm, ieeetr, apalike, ...
\bibliography{biblio}

%----------------------------------------------------------------------------------------

\end{multicols}

\end{document}
